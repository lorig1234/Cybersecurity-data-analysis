{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from collections import Counter\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer, LabelEncoder\n",
    "# from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # 1. Load and explore data\n",
    "# df = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "# print(\"Dataset shape:\", df.shape)\n",
    "# print(\"\\nTarget distribution:\")\n",
    "# print(df['Attack Type'].value_counts())\n",
    "# print(f\"\\nTarget distribution percentages:\")\n",
    "# print(df['Attack Type'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# # Check for missing values\n",
    "# print(\"\\nMissing values:\")\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "# # 2. Define features & target\n",
    "# TARGET = 'Attack Type'\n",
    "# X = df.drop(columns=[TARGET])\n",
    "# y = df[TARGET]\n",
    "\n",
    "# # 3. Encode target labels\n",
    "# le = LabelEncoder()\n",
    "# y_enc = le.fit_transform(y)\n",
    "# print(f\"\\nClass mapping: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "\n",
    "# # 4. Split train/test with stratification\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    "# )\n",
    "\n",
    "# print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "# print(f\"Test set size: {X_test.shape[0]}\")\n",
    "# print(f\"Training class distribution: {Counter(y_train)}\")\n",
    "\n",
    "# # 5. Feature engineering improvements\n",
    "# numeric_features = ['Number of Affected Users', 'Incident Resolution Time (in Hours)', 'Year']\n",
    "# categorical_features = ['Country', 'Target Industry', 'Attack Source', \n",
    "#                        'Security Vulnerability Type', 'Defense Mechanism Used']\n",
    "\n",
    "# # Check if outlier flags exist and include them\n",
    "# outlier_flags = [col for col in X.columns if 'outlier' in col.lower()]\n",
    "# if outlier_flags:\n",
    "#     print(f\"\\nFound outlier flags: {outlier_flags}\")\n",
    "#     categorical_features.extend(outlier_flags)\n",
    "\n",
    "# # 6. Improved preprocessors\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler()),\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')),\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "#     ('cat', categorical_transformer, categorical_features),\n",
    "# ], remainder='drop')\n",
    "\n",
    "# # 7. Improved XGBoost with better parameters for multiclass\n",
    "# xgb_clf = XGBClassifier(\n",
    "#     objective='multi:softprob',\n",
    "#     eval_metric='mlogloss',\n",
    "#     tree_method='hist',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     # Better starting parameters\n",
    "#     n_estimators=200,\n",
    "#     max_depth=6,\n",
    "#     learning_rate=0.1,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     reg_alpha=0.1,\n",
    "#     reg_lambda=1.0,\n",
    "# )\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('prep', preprocessor),\n",
    "#     ('clf', xgb_clf),\n",
    "# ])\n",
    "\n",
    "# # 8. Baseline evaluation with multiple metrics\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Test multiple scoring metrics\n",
    "# scoring_metrics = ['accuracy', 'f1_macro', 'f1_weighted']\n",
    "# for metric in scoring_metrics:\n",
    "#     scores = cross_val_score(pipe, X_train, y_train, scoring=metric, cv=cv)\n",
    "#     print(f'Baseline {metric}: {scores.mean():.3f} ¬± {scores.std():.3f}')\n",
    "\n",
    "# # 9. More comprehensive hyperparameter tuning\n",
    "# param_dist = {\n",
    "#     'clf__n_estimators': [100, 200, 300, 500],\n",
    "#     'clf__max_depth': [3, 4, 6, 8],\n",
    "#     'clf__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#     'clf__subsample': [0.6, 0.8, 0.9],\n",
    "#     'clf__colsample_bytree': [0.6, 0.8, 0.9],\n",
    "#     'clf__reg_alpha': [0, 0.1, 0.5],\n",
    "#     'clf__reg_lambda': [0.5, 1.0, 2.0],\n",
    "#     'clf__min_child_weight': [1, 3, 5],\n",
    "# }\n",
    "\n",
    "# print(\"\\nStarting hyperparameter tuning...\")\n",
    "# search = RandomizedSearchCV(\n",
    "#     pipe, param_distributions=param_dist,\n",
    "#     n_iter=50,  # Increased iterations\n",
    "#     cv=cv,\n",
    "#     scoring='f1_weighted',  # Better metric for imbalanced classes\n",
    "#     random_state=42, \n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# print(f'\\nBest CV F1-weighted: {search.best_score_:.3f}')\n",
    "# print('Best params:', search.best_params_)\n",
    "\n",
    "# # 10. Final evaluation\n",
    "# best_model = search.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# print(f'\\nTest Accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "# print('\\nClassification Report:')\n",
    "# print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# # 11. Additional diagnostics\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "\n",
    "# # Feature importance\n",
    "# feature_names = (numeric_features + \n",
    "#                 list(best_model.named_steps['prep'].named_transformers_['cat']\n",
    "#                      .named_steps['onehot'].get_feature_names_out(categorical_features)))\n",
    "\n",
    "# importances = best_model.named_steps['clf'].feature_importances_\n",
    "# feature_importance_df = pd.DataFrame({\n",
    "#     'feature': feature_names,\n",
    "#     'importance': importances\n",
    "# }).sort_values('importance', ascending=False)\n",
    "\n",
    "# print(\"\\nTop 10 Most Important Features:\")\n",
    "# print(feature_importance_df.head(10))\n",
    "\n",
    "# # 12. Prediction confidence analysis\n",
    "# print(\"\\nPrediction Confidence Analysis:\")\n",
    "# max_probas = np.max(y_pred_proba, axis=1)\n",
    "# print(f\"Average prediction confidence: {max_probas.mean():.3f}\")\n",
    "# print(f\"Predictions with confidence > 0.5: {(max_probas > 0.5).sum()}/{len(max_probas)}\")\n",
    "# print(f\"Predictions with confidence > 0.8: {(max_probas > 0.8).sum()}/{len(max_probas)}\")\n",
    "\n",
    "# # 13. Recommendations based on results\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"DIAGNOSTIC RECOMMENDATIONS:\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# if accuracy_score(y_test, y_pred) < 0.3:\n",
    "#     print(\"‚ö†Ô∏è  Very low accuracy detected. Possible issues:\")\n",
    "#     print(\"   - Data quality problems (mislabeled samples)\")\n",
    "#     print(\"   - Insufficient features for discrimination\")\n",
    "#     print(\"   - High class imbalance or noise\")\n",
    "#     print(\"   - Consider data cleaning and feature engineering\")\n",
    "\n",
    "# if max_probas.mean() < 0.4:\n",
    "#     print(\"‚ö†Ô∏è  Low prediction confidence suggests:\")\n",
    "#     print(\"   - Model uncertainty due to overlapping classes\")\n",
    "#     print(\"   - Consider ensemble methods or different algorithms\")\n",
    "#     print(\"   - Review feature selection and engineering\")\n",
    "\n",
    "# # Calculate class balance\n",
    "# class_counts = Counter(y_train)\n",
    "# min_class = min(class_counts.values())\n",
    "# max_class = max(class_counts.values())\n",
    "# imbalance_ratio = max_class / min_class\n",
    "\n",
    "# if imbalance_ratio > 2:\n",
    "#     print(f\"‚ö†Ô∏è  Class imbalance detected (ratio: {imbalance_ratio:.1f})\")\n",
    "#     print(\"   - Consider using class_weight='balanced' in XGBoost\")\n",
    "#     print(\"   - Try SMOTE or other resampling techniques\")\n",
    "#     print(\"   - Use stratified sampling more carefully\")\n",
    "\n",
    "# print(\"\\nüí° IMPROVEMENT SUGGESTIONS:\")\n",
    "# print(\"   1. Examine data quality and labeling accuracy\")\n",
    "# print(\"   2. Try feature selection/engineering\")\n",
    "# print(\"   3. Consider ensemble methods\")\n",
    "# print(\"   4. Experiment with different algorithms (Random Forest, Neural Networks)\")\n",
    "# print(\"   5. Use cross-validation with different metrics\")\n",
    "\n",
    "# # 14. Additional data exploration\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"ADDITIONAL DATA INSIGHTS:\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# # Check feature correlation with target\n",
    "# print(\"\\nNumeric features summary:\")\n",
    "# for col in numeric_features:\n",
    "#     if col in df.columns:\n",
    "#         print(f\"{col}: mean={df[col].mean():.2f}, std={df[col].std():.2f}, \"\n",
    "#               f\"min={df[col].min():.2f}, max={df[col].max():.2f}\")\n",
    "\n",
    "# # Check categorical feature cardinality\n",
    "# print(\"\\nCategorical features cardinality:\")\n",
    "# for col in categorical_features:\n",
    "#     if col in df.columns and 'outlier' not in col.lower():\n",
    "#         unique_vals = df[col].nunique()\n",
    "#         print(f\"{col}: {unique_vals} unique values\")\n",
    "#         if unique_vals < 20:  # Show values if not too many\n",
    "#             print(f\"   Values: {list(df[col].unique())}\")\n",
    "\n",
    "# # Save detailed results for further analysis\n",
    "# results_dict = {\n",
    "#     'test_accuracy': accuracy_score(y_test, y_pred),\n",
    "#     'best_cv_score': search.best_score_,\n",
    "#     'best_params': search.best_params_,\n",
    "#     'feature_importance': feature_importance_df.to_dict(),\n",
    "#     'class_distribution': dict(Counter(y_train)),\n",
    "#     'prediction_confidence': {\n",
    "#         'mean': max_probas.mean(),\n",
    "#         'confident_predictions_50': (max_probas > 0.5).sum(),\n",
    "#         'confident_predictions_80': (max_probas > 0.8).sum(),\n",
    "#         'total_predictions': len(max_probas)\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# print(f\"\\nModel saved results summary:\")\n",
    "# print(f\"Final test accuracy: {results_dict['test_accuracy']:.3f}\")\n",
    "# print(f\"Best CV F1-weighted: {results_dict['best_cv_score']:.3f}\")\n",
    "\n",
    "# # 15. Try a simple baseline for comparison\n",
    "# from sklearn.dummy import DummyClassifier\n",
    "# dummy_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "# dummy_clf.fit(X_train, y_train)\n",
    "# dummy_pred = dummy_clf.predict(X_test)\n",
    "# dummy_accuracy = accuracy_score(y_test, dummy_pred)\n",
    "# print(f\"\\nBaseline (most frequent class) accuracy: {dummy_accuracy:.3f}\")\n",
    "# print(f\"Model improvement over baseline: {(results_dict['test_accuracy'] - dummy_accuracy):.3f}\")\n",
    "\n",
    "# if results_dict['test_accuracy'] <= dummy_accuracy + 0.05:\n",
    "#     print(\"‚ö†Ô∏è  WARNING: Model barely outperforms random baseline!\")\n",
    "#     print(\"   This suggests the features may not be predictive of the target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fe5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"Global_Cybersecurity_Threats_2015-2024.csv\")\n",
    "\n",
    "# # Drop rows where Attack Type (the label) is missing\n",
    "# df = df.dropna(subset=[\"Attack Type\"]).reset_index(drop=True)\n",
    "\n",
    "# # Optional: remove obvious duplicates\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = df.drop(columns=[\"Attack Type\"])\n",
    "# y = df[\"Attack Type\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.20, stratify=y, random_state=42\n",
    "# )\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# # Identify categorical feature indices (CatBoost needs positions, not names)\n",
    "# cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "# cat_features = [X.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "# clf = CatBoostClassifier(\n",
    "#     iterations      = 1500,        # plenty of trees; use early stopping\n",
    "#     learning_rate   = 0.03,\n",
    "#     depth           = 6,\n",
    "#     loss_function   = \"MultiClass\",\n",
    "#     eval_metric     = \"TotalF1\",    # macro F1 = good for 6-class target\n",
    "#     random_seed     = 42,\n",
    "#     auto_class_weights = \"Balanced\",\n",
    "#     cat_features    = cat_features,\n",
    "#     verbose         = 100\n",
    "# )\n",
    "\n",
    "# clf.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=(X_test, y_test),\n",
    "#     early_stopping_rounds=100\n",
    "# )\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feat_imp = clf.get_feature_importance(prettified=True)\n",
    "# feat_imp.head(15).plot(kind=\"barh\", x=\"Feature Id\", y=\"Importances\", figsize=(6,6))\n",
    "# plt.title(\"CatBoost ‚Äì Feature Importance (Top 15)\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # # 2) Model\n",
    "# # clf = CatBoostClassifier(\n",
    "# #     iterations=1500, learning_rate=0.03, depth=6, loss_function=\"MultiClass\",\n",
    "# #     eval_metric=\"TotalF1\", random_seed=42, auto_class_weights=\"Balanced\",\n",
    "# #     cat_features=cat_features, verbose=100\n",
    "# # )\n",
    "\n",
    "# # # 3) Fit + early stopping\n",
    "# # clf.fit(X_train, y_train,\n",
    "# #         eval_set=(X_test, y_test),\n",
    "# #         early_stopping_rounds=100)\n",
    "\n",
    "# # # 4) Metrics\n",
    "# # from sklearn.metrics import classification_report\n",
    "# # print(classification_report(y_test, clf.predict(X_test), digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
